{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone \n",
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone_api_key = 'ad71b023-81cd-4946-bc21-2c18b51f9e6a'\n",
    "pinecone.init(\n",
    "    api_key=pinecone_api_key,  # find at app.pinecone.io\n",
    "    environment='asia-southeast1-gcp-free'  # next to api key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = config.api_keys['openai_api_image_key']\n",
    "# %%\n",
    "embeddings = OpenAIEmbeddings(disallowed_special=(), openai_api_key=openai_api_key)\n",
    "\n",
    "from langchain.document_loaders import TextLoader\n",
    "loader = TextLoader('./waitbutwhy.csv')\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000, \n",
    "    chunk_overlap = 50,\n",
    "    length_function = len)\n",
    "\n",
    "docs = text_splitter.split_documents(documents) # list of lists of strings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'tim-urban-test'\n",
    "#upload vectors \n",
    "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Write a blog about marriage?\"\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to tell it. Wedding day came and went. People in my life were worried about me. They tried encouraging me, shaming me, setting deadlines for me, reminding me that one post really shouldn’t take multiple years. Nothing seemed to help. Finally, in mid-2019, I hatched a plan that would once and for all end this thing. Rather than post a gargantuan blog post, I’d make it a series . This would break it into parts, which is less daunting. Plus, I had learned that the adrenaline of knowing that my readers were only days away from seeing what I was working on was a huge motivator that I had been sorely missing. I called it The Story of Us and in August of 2019, the first chapter went up. The whole thing would be 12 chapters, I decided, and even though the chapters got longer as they went, and the time between them expanded, it was finally happening—I was publishing the damn thing. The end was near. Then came Chapter 11. The first 10 chapters had introduced the core framework of the series and\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k-0613', openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "template ='''\n",
    "Use the following pieces of context from waitbutwhy to answer the question at the end. \n",
    "If you don't know the answer, just clarify that you are not sure, but this might be how Tim Urban thinks.\n",
    "'''\n",
    "user_input = '''Write a post about marriage within 300 words like waitbutwhy using \"you\" in a casual language'''\n",
    "final_input = template+ store+ user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, you're thinking about getting married, huh? Well, let me tell you, it's not all rainbows and butterflies. I mean, sure, there's the whole \"happily ever after\" thing, but there's also a lot of hard work involved.\n",
      "\n",
      "You see, marriage is like a rollercoaster ride. There are ups and downs, twists and turns, and moments where you just want to scream. But at the end of the day, it's worth it. Because when you find that person who makes you laugh, supports you through thick and thin, and loves you unconditionally, it's like finding your other half.\n",
      "\n",
      "Now, I'm not saying it's going to be easy. There will be disagreements, arguments, and moments where you question everything. But that's all part of the journey. It's about learning to compromise, communicate, and grow together.\n",
      "\n",
      "And let me tell you, there's nothing quite like the feeling of coming home to your best friend every day. Someone who knows you inside and out, who accepts you for who you are, flaws and all. They're your partner in crime, your confidant, and your biggest cheerleader.\n",
      "\n",
      "But here's the thing, marriage isn't just about the two of you. It's about building a life together, creating a family, and navigating the ups and downs of life side by side. It's about supporting each other's dreams and pushing each other to be the best versions of yourselves.\n",
      "\n",
      "So, if you're ready to take the plunge, go for it. But remember, it's not just about the wedding day or the fancy rings. It's about the commitment, the love, and the shared adventure that lies ahead. And trust me, it's a ride you won't want to miss.\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "chat = ChatOpenAI(model_name='gpt-3.5-turbo-16k-0613', openai_api_key=openai_api_key)   \n",
    "\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=template+store),\n",
    "    HumanMessage(content=user_input)\n",
    "]\n",
    "response=chat(messages)\n",
    "\n",
    "print(response.content,end='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tim-urban-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
